{
  "best_model_name": "random_forest",
  "best_score": 0.5149836313271215,
  "all_results": {
    "random_forest": {
      "accuracy": 0.5727121464226289,
      "precision": 0.5599671412924425,
      "recall": 0.4766899766899767,
      "f1_score": 0.5149836313271215,
      "roc_auc": 0.5996428756428756,
      "confusion_matrix": [
        [
          2045,
          2245
        ],
        [
          1607,
          3118
        ]
      ],
      "classification_report": {
        "good_match": {
          "precision": 0.5599671412924425,
          "recall": 0.4766899766899767,
          "f1-score": 0.5149836313271215,
          "support": 4290.0
        },
        "poor_match": {
          "precision": 0.5813910124930076,
          "recall": 0.6598941798941799,
          "f1-score": 0.6181601903251387,
          "support": 4725.0
        },
        "accuracy": 0.5727121464226289,
        "macro avg": {
          "precision": 0.570679076892725,
          "recall": 0.5682920782920783,
          "f1-score": 0.5665719108261301,
          "support": 9015.0
        },
        "weighted avg": {
          "precision": 0.5711959589765989,
          "recall": 0.5727121464226289,
          "f1-score": 0.5690611955274134,
          "support": 9015.0
        }
      },
      "cv_f1_mean": 0.5302914937689388,
      "cv_f1_std": 0.003403284640008187
    },
    "gradient_boosting": {
      "accuracy": 0.5690515806988353,
      "precision": 0.560106856634016,
      "recall": 0.4398601398601399,
      "f1_score": 0.49275362318840576,
      "roc_auc": 0.5972396245729579,
      "confusion_matrix": [
        [
          1887,
          2403
        ],
        [
          1482,
          3243
        ]
      ],
      "classification_report": {
        "good_match": {
          "precision": 0.560106856634016,
          "recall": 0.4398601398601399,
          "f1-score": 0.49275362318840576,
          "support": 4290.0
        },
        "poor_match": {
          "precision": 0.5743889479277364,
          "recall": 0.6863492063492064,
          "f1-score": 0.6253977437084177,
          "support": 4725.0
        },
        "accuracy": 0.5690515806988353,
        "macro avg": {
          "precision": 0.5672479022808763,
          "recall": 0.5631046731046732,
          "f1-score": 0.5590756834484117,
          "support": 9015.0
        },
        "weighted avg": {
          "precision": 0.5675924785267314,
          "recall": 0.5690515806988353,
          "f1-score": 0.562275915973437,
          "support": 9015.0
        }
      },
      "cv_f1_mean": 0.5394969662411345,
      "cv_f1_std": 0.006647550520741582
    },
    "logistic_regression": {
      "accuracy": 0.547642817526345,
      "precision": 0.5316606929510155,
      "recall": 0.4149184149184149,
      "f1_score": 0.4660905996334119,
      "roc_auc": 0.5612333345666679,
      "confusion_matrix": [
        [
          1780,
          2510
        ],
        [
          1568,
          3157
        ]
      ],
      "classification_report": {
        "good_match": {
          "precision": 0.5316606929510155,
          "recall": 0.4149184149184149,
          "f1-score": 0.4660905996334119,
          "support": 4290.0
        },
        "poor_match": {
          "precision": 0.5570848773601553,
          "recall": 0.6681481481481482,
          "f1-score": 0.6075827559661278,
          "support": 4725.0
        },
        "accuracy": 0.547642817526345,
        "macro avg": {
          "precision": 0.5443727851555854,
          "recall": 0.5415332815332815,
          "f1-score": 0.5368366777997698,
          "support": 9015.0
        },
        "weighted avg": {
          "precision": 0.5449861806196994,
          "recall": 0.547642817526345,
          "f1-score": 0.5402503820706922,
          "support": 9015.0
        }
      },
      "cv_f1_mean": 0.5262533025356735,
      "cv_f1_std": 0.009844914809342407
    },
    "svm": {
      "accuracy": 0.5729339988907377,
      "precision": 0.5674019607843137,
      "recall": 0.4317016317016317,
      "f1_score": 0.49033624569764367,
      "roc_auc": 0.593655110321777,
      "confusion_matrix": [
        [
          1852,
          2438
        ],
        [
          1412,
          3313
        ]
      ],
      "classification_report": {
        "good_match": {
          "precision": 0.5674019607843137,
          "recall": 0.4317016317016317,
          "f1-score": 0.49033624569764367,
          "support": 4290.0
        },
        "poor_match": {
          "precision": 0.5760737263084681,
          "recall": 0.7011640211640212,
          "f1-score": 0.6324933180603285,
          "support": 4725.0
        },
        "accuracy": 0.5729339988907377,
        "macro avg": {
          "precision": 0.5717378435463909,
          "recall": 0.5664328264328264,
          "f1-score": 0.5614147818789861,
          "support": 9015.0
        },
        "weighted avg": {
          "precision": 0.5719470625149436,
          "recall": 0.5729339988907377,
          "f1-score": 0.5648445282171873,
          "support": 9015.0
        }
      },
      "cv_f1_mean": 0.5280887027407309,
      "cv_f1_std": 0.006426626425919567
    }
  },
  "training_date": "2025-09-07T10:16:20.624625",
  "data_shape": [
    36056,
    33
  ],
  "feature_count": 19
}